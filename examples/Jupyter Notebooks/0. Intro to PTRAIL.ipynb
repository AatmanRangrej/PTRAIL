{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<!---------------------- Introduction Section ------------------->\n",
    "<h1> PTRAIL:  A <b><i>P</i></b>arallel\n",
    "<b><i>TR</i></b>ajectory\n",
    "d<b><i>A</i></b>ta\n",
    "preprocess<b><i>I</i></b>ng\n",
    "<b><i>L</i></b>ibrary\n",
    "</h1>\n",
    "\n",
    "<h2> Introduction </h2>\n",
    "\n",
    "<p align='justify'>\n",
    "PTRAIL is a state-of-the art Mobility Data Preprocessing Library that mainly deals with filtering data, generating features and interpolation of Trajectory Data.\n",
    "\n",
    "<b><i> The main features of PTRAIL are: </i></b>\n",
    "\n",
    "<ol align='justify'>\n",
    "<li> PTRAIL uses primarily parallel computation based on\n",
    "     python Pandas and numpy which makes it very fast as compared\n",
    "     to other libraries available.\n",
    "</li>\n",
    "\n",
    "<li> PTRAIL harnesses the full power of the machine that\n",
    "     it is running on by using all the cores available in the\n",
    "     computer.\n",
    "</li>\n",
    "\n",
    "<li> PTRAIL uses a customized DataFrame built on top of python\n",
    "     pandas for representation and storage of Trajectory Data.\n",
    "</li>\n",
    "\n",
    "<li> PTRAIL also provides several Temporal and kinematic features\n",
    "     which are calculated mostly using parallel computation for very\n",
    "     fast and accurate calculations.\n",
    "</li>\n",
    "\n",
    "<li> Moreover, PTRAIL also provides several filteration and\n",
    "     outlier detection methods for cleaning and noise reduction of\n",
    "     the Trajectory Data.\n",
    "</li>\n",
    "\n",
    "<li> Apart from the features mentioned above, <i><b> four </b></i>\n",
    "     different kinds of Trajectory Interpolation techniques are\n",
    "     offered by PTRAIL which is a first in the community.\n",
    "</li>\n",
    "</ol>\n",
    "</p>\n",
    "\n",
    "<!----------------- Dataset Link Section --------------------->\n",
    "<hr style=\"height:6px;background-color:black\">\n",
    "\n",
    "<p align='justify'>\n",
    "In the introduction of the library, the seagulls dataset is used\n",
    "which can be downloaded from the link below: <br>\n",
    "<span> &#8618; </span>\n",
    "<a href=\"https://github.com/YakshHaranwala/PTRAIL/blob/main/examples/data/gulls.csv\" target='_blank'> Seagulls Dataset </a>\n",
    "</p>\n",
    "\n",
    "<!----------------- NbViewer Link ---------------------------->\n",
    "<hr style=\"height:6px;background-color:black\">\n",
    "<p align='justify'>\n",
    "Note: Viewing this notebook in GitHub will not render JavaScript\n",
    "elements. Hence, for a better experience, click the link below\n",
    "to open the Jupyter notebook in NB viewer.\n",
    "\n",
    "<span> &#8618; </span>\n",
    "<a href=\"https://nbviewer.jupyter.org/github/YakshHaranwala/PTRAIL/blob/main/examples/0.%20Intro%20to%20PTRAIL.ipynb\" target='_blank'> Click Here </a>\n",
    "</p>\n",
    "\n",
    "<!------------------------- Documentation Link ----------------->\n",
    "<hr style=\"height:6px;background-color:black\">\n",
    "<p align='justify'>\n",
    "The Link to PTRAIL's Documentation is: <br>\n",
    "\n",
    "<span> &#8618; </span>\n",
    "<a href='https://PTRAIL.readthedocs.io/en/latest/' target='_blank'> <i> PTRAIL Documentation </i> </a>\n",
    "<hr style=\"height:6px;background-color:black\">\n",
    "</p>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Importing Trajectory Data into a PTRAILDataFrame Dataframe </h2>\n",
    "\n",
    "<p align='justify'>\n",
    "PTRAIL Library stores Mobility Data (Trajectories) in a specialised\n",
    "pandas Dataframe structure called PTRAILDataFrame. As a result, the following\n",
    "constraints are enforced for the data to be able to be stores in a PTRAILDataFrame.\n",
    "\n",
    "<ol align='justify'>\n",
    "   <li>\n",
    "        Firstly, for a mobility dataset to be able to work with PTRAIL Library needs\n",
    "        to have the following mandatory columns present:\n",
    "       <ul type='square'>\n",
    "           <li> DateTime </li>\n",
    "           <li> Trajectory ID </li>\n",
    "           <li> Latitude </li>\n",
    "           <li> Longitude </li>\n",
    "       </ul>\n",
    "   </li>\n",
    "   <li>\n",
    "       Secondly, PTRAILDataFrame has a very specific constraint for the index of the\n",
    "       dataframes, the Library enforces a multi-index consisting of the\n",
    "       <b><i> Trajectory ID, DateTime </i></b> columns because the operations of the\n",
    "       library are dependent on the 2 columns. As a result, it is recommended\n",
    "       to not change the index and keep the multi-index of <b><i> Trajectory ID, DateTime </i></b>\n",
    "       at all times.\n",
    "   </li>\n",
    "   <li>\n",
    "        Note that since PTRAILDataFrame Dataframe is built on top of\n",
    "        python pandas, it does not have any restrictions on the number\n",
    "        of columns that the dataset has. The only requirement is that\n",
    "        the dataset should atleast contain the above mentioned four columns.\n",
    "   </li>\n",
    "</ol>\n",
    "</p>\n",
    "\n",
    "<hr style=\"height:6px;background-color:black\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the dataframe:(6, 2)\n",
      "Type of the dataframe: <class 'ptrail.core.TrajectoryDF.PTRAILDataFrame'>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    METHOD - I:\n",
    "        1. Enter the trajectory data into a list.\n",
    "        2. Then, convert the list into a PTRAILDataFrame\n",
    "           Dataframe to be used with PTRAIL Library.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from ptrail.core.TrajectoryDF import PTRAILDataFrame\n",
    "\n",
    "list_data = [\n",
    "    [39.984094, 116.319236, '2008-10-23 05:53:05', 1],\n",
    "    [39.984198, 116.319322, '2008-10-23 05:53:06', 1],\n",
    "    [39.984224, 116.319402, '2008-10-23 05:53:11', 1],\n",
    "    [39.984224, 116.319404, '2008-10-23 05:53:11', 1],\n",
    "    [39.984224, 116.568956, '2008-10-23 05:53:11', 1],\n",
    "    [39.984224, 116.568956, '2008-10-23 05:53:11', 1]\n",
    "]\n",
    "list_df = PTRAILDataFrame(data_set=list_data,\n",
    "                        latitude='lat',\n",
    "                        longitude='lon',\n",
    "                        datetime='datetime',\n",
    "                        traj_id='id')\n",
    "print(f\"The dimensions of the dataframe:{list_df.shape}\")\n",
    "print(f\"Type of the dataframe: {type(list_df)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the dataframe:(5, 2)\n",
      "Type of the dataframe: <class 'ptrail.core.TrajectoryDF.PTRAILDataFrame'>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    METHOD - II:\n",
    "        1. Enter the trajectory data into a dictionary.\n",
    "        2. Then, convert the dictionary into a PTRAILDataFrame\n",
    "           Dataframe to be used with PTRAIL Library.\n",
    "\"\"\"\n",
    "dict_data = {\n",
    "    'lat': [39.984198, 39.984224, 39.984094, 40.98, 41.256],\n",
    "    'lon': [116.319402, 116.319322, 116.319402, 116.3589, 117],\n",
    "    'datetime': ['2008-10-23 05:53:11', '2008-10-23 05:53:06', '2008-10-23 05:53:30', '2008-10-23 05:54:06', '2008-10-23 05:59:06'],\n",
    "    'id' : [1, 1, 1, 3, 3],\n",
    "}\n",
    "dict_df = PTRAILDataFrame(data_set=dict_data,\n",
    "                        latitude='lat',\n",
    "                        longitude='lon',\n",
    "                        datetime='datetime',\n",
    "                        traj_id='id')\n",
    "print(f\"The dimensions of the dataframe:{dict_df.shape}\")\n",
    "print(f\"Type of the dataframe: {type(dict_df)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                   lat         lon\ntraj_id DateTime                                  \n1       2008-10-23 05:53:05  39.984094  116.319236\n        2008-10-23 05:53:06  39.984198  116.319322\n        2008-10-23 05:53:11  39.984224  116.319402\n        2008-10-23 05:53:11  39.984224  116.319404\n        2008-10-23 05:53:11  39.984224  116.568956",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>lat</th>\n      <th>lon</th>\n    </tr>\n    <tr>\n      <th>traj_id</th>\n      <th>DateTime</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">1</th>\n      <th>2008-10-23 05:53:05</th>\n      <td>39.984094</td>\n      <td>116.319236</td>\n    </tr>\n    <tr>\n      <th>2008-10-23 05:53:06</th>\n      <td>39.984198</td>\n      <td>116.319322</td>\n    </tr>\n    <tr>\n      <th>2008-10-23 05:53:11</th>\n      <td>39.984224</td>\n      <td>116.319402</td>\n    </tr>\n    <tr>\n      <th>2008-10-23 05:53:11</th>\n      <td>39.984224</td>\n      <td>116.319404</td>\n    </tr>\n    <tr>\n      <th>2008-10-23 05:53:11</th>\n      <td>39.984224</td>\n      <td>116.568956</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, printing the head of the dataframe with data\n",
    "# imported from a list.\n",
    "list_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                   lat         lon\ntraj_id DateTime                                  \n1       2008-10-23 05:53:06  39.984224  116.319322\n        2008-10-23 05:53:11  39.984198  116.319402\n        2008-10-23 05:53:30  39.984094  116.319402\n3       2008-10-23 05:54:06  40.980000  116.358900\n        2008-10-23 05:59:06  41.256000  117.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>lat</th>\n      <th>lon</th>\n    </tr>\n    <tr>\n      <th>traj_id</th>\n      <th>DateTime</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">1</th>\n      <th>2008-10-23 05:53:06</th>\n      <td>39.984224</td>\n      <td>116.319322</td>\n    </tr>\n    <tr>\n      <th>2008-10-23 05:53:11</th>\n      <td>39.984198</td>\n      <td>116.319402</td>\n    </tr>\n    <tr>\n      <th>2008-10-23 05:53:30</th>\n      <td>39.984094</td>\n      <td>116.319402</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">3</th>\n      <th>2008-10-23 05:54:06</th>\n      <td>40.980000</td>\n      <td>116.358900</td>\n    </tr>\n    <tr>\n      <th>2008-10-23 05:59:06</th>\n      <td>41.256000</td>\n      <td>117.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, printing the head of the dataframe with data\n",
    "# imported from a dictionary.\n",
    "dict_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    METHOD - III:\n",
    "        1. First, import the seagulls dataset from the csv file\n",
    "           using pandas into a pandas dataframe.\n",
    "        2. Then, convert the pandas dataframe into a PTRAILDataFrame\n",
    "           DataFrame to be used with PTRAIL library.\n",
    "\"\"\"\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/YakshHaranwala/PTRAIL/main/examples/data/seagulls.csv')\n",
    "seagulls_df = PTRAILDataFrame(data_set=df,\n",
    "                            latitude='lat',\n",
    "                            longitude='long',\n",
    "                            datetime='DateTime',\n",
    "                            traj_id='traj_id',\n",
    "                            rest_of_columns=[])\n",
    "print(f\"The dimensions of the dataframe:{seagulls_df.shape}\")\n",
    "print(f\"Type of the dataframe: {type(seagulls_df)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_104972/3801869193.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m            \u001B[0mDataFrame\u001B[0m \u001B[0mto\u001B[0m \u001B[0mbe\u001B[0m \u001B[0mused\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mPTRAIL\u001B[0m \u001B[0mlibrary\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \"\"\"\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'https://raw.githubusercontent.com/YakshHaranwala/PTRAIL/main/examples/data/seagulls.csv'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m seagulls_df = PTRAILDataFrame(data_set=df,\n\u001B[1;32m     10\u001B[0m                             \u001B[0mlatitude\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'lat'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    608\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    609\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 610\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    611\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    612\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    460\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    461\u001B[0m     \u001B[0;31m# Create the parser.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 462\u001B[0;31m     \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    463\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    464\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    817\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    818\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 819\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    820\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    821\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[0;34m(self, engine)\u001B[0m\n\u001B[1;32m   1048\u001B[0m             )\n\u001B[1;32m   1049\u001B[0m         \u001B[0;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1050\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[call-arg]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1051\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1052\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_failover_to_python\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m   1865\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1866\u001B[0m         \u001B[0;31m# open handles\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1867\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1868\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1869\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mkey\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m\"storage_options\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"encoding\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"memory_map\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"compression\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_open_handles\u001B[0;34m(self, src, kwds)\u001B[0m\n\u001B[1;32m   1360\u001B[0m         \u001B[0mLet\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mreaders\u001B[0m \u001B[0mopen\u001B[0m \u001B[0mIOHanldes\u001B[0m \u001B[0mafter\u001B[0m \u001B[0mthey\u001B[0m \u001B[0mare\u001B[0m \u001B[0mdone\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mtheir\u001B[0m \u001B[0mpotential\u001B[0m \u001B[0mraises\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1361\u001B[0m         \"\"\"\n\u001B[0;32m-> 1362\u001B[0;31m         self.handles = get_handle(\n\u001B[0m\u001B[1;32m   1363\u001B[0m             \u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1364\u001B[0m             \u001B[0;34m\"r\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/site-packages/pandas/io/common.py\u001B[0m in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    556\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    557\u001B[0m     \u001B[0;31m# open URLs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 558\u001B[0;31m     ioargs = _get_filepath_or_buffer(\n\u001B[0m\u001B[1;32m    559\u001B[0m         \u001B[0mpath_or_buf\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    560\u001B[0m         \u001B[0mencoding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mencoding\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/site-packages/pandas/io/common.py\u001B[0m in \u001B[0;36m_get_filepath_or_buffer\u001B[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001B[0m\n\u001B[1;32m    287\u001B[0m                 \u001B[0;34m\"storage_options passed with file object or non-fsspec file path\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    288\u001B[0m             )\n\u001B[0;32m--> 289\u001B[0;31m         \u001B[0mreq\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0murlopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    290\u001B[0m         \u001B[0mcontent_encoding\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mreq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mheaders\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Content-Encoding\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    291\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcontent_encoding\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"gzip\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/site-packages/pandas/io/common.py\u001B[0m in \u001B[0;36murlopen\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    193\u001B[0m     \u001B[0;32mimport\u001B[0m \u001B[0murllib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    194\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 195\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0murllib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0murlopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    196\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    197\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/urllib/request.py\u001B[0m in \u001B[0;36murlopen\u001B[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001B[0m\n\u001B[1;32m    220\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    221\u001B[0m         \u001B[0mopener\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_opener\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 222\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mopener\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    223\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    224\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0minstall_opener\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopener\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/urllib/request.py\u001B[0m in \u001B[0;36mopen\u001B[0;34m(self, fullurl, data, timeout)\u001B[0m\n\u001B[1;32m    529\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mprocessor\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprocess_response\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    530\u001B[0m             \u001B[0mmeth\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprocessor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmeth_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 531\u001B[0;31m             \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmeth\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreq\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    532\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    533\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/urllib/request.py\u001B[0m in \u001B[0;36mhttp_response\u001B[0;34m(self, request, response)\u001B[0m\n\u001B[1;32m    638\u001B[0m         \u001B[0;31m# request was successfully received, understood, and accepted.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    639\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m200\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0mcode\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m300\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 640\u001B[0;31m             response = self.parent.error(\n\u001B[0m\u001B[1;32m    641\u001B[0m                 'http', request, response, code, msg, hdrs)\n\u001B[1;32m    642\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/urllib/request.py\u001B[0m in \u001B[0;36merror\u001B[0;34m(self, proto, *args)\u001B[0m\n\u001B[1;32m    567\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mhttp_err\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    568\u001B[0m             \u001B[0margs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mdict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'default'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'http_error_default'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0morig_args\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 569\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call_chain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    570\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    571\u001B[0m \u001B[0;31m# XXX probably also want an abstract factory that knows when it makes\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/urllib/request.py\u001B[0m in \u001B[0;36m_call_chain\u001B[0;34m(self, chain, kind, meth_name, *args)\u001B[0m\n\u001B[1;32m    500\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mhandler\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mhandlers\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    501\u001B[0m             \u001B[0mfunc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhandler\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmeth_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 502\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    503\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mresult\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    504\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/urllib/request.py\u001B[0m in \u001B[0;36mhttp_error_default\u001B[0;34m(self, req, fp, code, msg, hdrs)\u001B[0m\n\u001B[1;32m    647\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mHTTPDefaultErrorHandler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mBaseHandler\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    648\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mhttp_error_default\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreq\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmsg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhdrs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 649\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mHTTPError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfull_url\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmsg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhdrs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    650\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    651\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mHTTPRedirectHandler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mBaseHandler\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mHTTPError\u001B[0m: HTTP Error 404: Not Found"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    # Now, print the head of the seagulls_df dataframe.\n",
    "seagulls_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Trajectory Feature Extraction </h1>\n",
    "\n",
    "<p align='justify'>\n",
    "As mentioned above, PTRAIL offers a multitude of features\n",
    "which are calculated based on both Datetime, and the coordinates\n",
    "of the points given in the data. Both the feature module are named\n",
    "as follows:\n",
    "</p>\n",
    "\n",
    "<ul align='justify'>\n",
    "    <li> temporal_features (based on DateTime) </li>\n",
    "    <li> kinematic_features (based on geographical coordinates) </li>\n",
    "</ul>\n",
    "<hr style=\"background-color:black; height:7px\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> PTRAIL Temporal Features </h2>\n",
    "\n",
    "<p align='justify'>\n",
    "\n",
    "The following steps are performed to demonstrate the usage of\n",
    "Temporal features present in PTRAIL:\n",
    "\n",
    "<ul type='square', align='justify'>\n",
    "<li>Various features Date, Time, Week-day, Time of Day etc are\n",
    "    calculated using temporal_features.py module functions and\n",
    "    the results are appended to the original dataframe.\n",
    "</li>\n",
    "<li> Not all the functions present in the module are demonstrated\n",
    "     here. Only a few of the functions are demonstrated here, keeping\n",
    "     the length of jupyter notebook in mind. Further functions can\n",
    "     be explored in the documentation of the library. The documentation\n",
    "     link is provided in the introduction section of this notebook.\n",
    "</li>\n",
    "</ul>\n",
    "</p>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\"\n",
    "    To demonstrate the temporal features, we will:\n",
    "        1. First, import the temporal_features.py module from the\n",
    "           features package.\n",
    "        2. Generate Date, Day_Of_Week, Time_Of_day features on\n",
    "           the seagulls dataset.\n",
    "        3. Print the execution time of the code.\n",
    "        4. Finally, check the head of the dataframe to\n",
    "           see the results of feature generation.\n",
    "\"\"\"\n",
    "from ptrail.features.temporal_features import TemporalFeatures as temporal\n",
    "\n",
    "temporal_features_df = temporal.create_date_column(seagulls_df)\n",
    "temporal_features_df = temporal.create_day_of_week_column(temporal_features_df)\n",
    "temporal_features_df = temporal.create_time_of_day_column(temporal_features_df)\n",
    "temporal_features_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> PTRAIL kinematic Features </h2>\n",
    "\n",
    "<p align='justify'>\n",
    "\n",
    "The following steps are performed to demonstrate the usage of\n",
    "kinematic features present in PTRAIL:\n",
    "</p>\n",
    "<ul type='square', align='justify'>\n",
    "<li>Various features like Distance, Jerk and rate of bearing rate are\n",
    "    calculated using kinematic_features.py module functions and\n",
    "    the results are appended to the original dataframe.\n",
    "</li>\n",
    "<li> While calculating jerk, the columns of acceleration, speed and\n",
    "     distance all are added to the dataframe. Similarly, when calculating\n",
    "     rate of bearing rate, the column of Bearing and Bearing rate are\n",
    "     added to the dataframe.\n",
    "</li>\n",
    "<li> Not all the functions present in the module are demonstrated\n",
    "     here. Only a few of the functions are demonstrated here, keeping\n",
    "     the length of jupyter notebook in mind. Further functions can\n",
    "     be explored in the documentation of the library. The documentation\n",
    "     link is provided in the introduction section of this notebook.\n",
    "</li>\n",
    "</ul>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\"\n",
    "    To demonstrate the kinematic features, we will:\n",
    "        1. First, import the kinematic_features.py module from the\n",
    "           features package.\n",
    "        2. Calculate Distance, Jerk and Rate of bearing rate features on\n",
    "           the seagulls dataset.\n",
    "        3. Print the execution time of the code.\n",
    "        4. Finally, check the head of the dataframe to\n",
    "           see the results of feature generation.\n",
    "\"\"\"\n",
    "\n",
    "from ptrail.features.kinematic_features import KinematicFeatures as kinematic\n",
    "\n",
    "kinematic_features_df = kinematic.create_distance_column(seagulls_df)\n",
    "kinematic_features_df = kinematic.create_jerk_column(kinematic_features_df)\n",
    "kinematic_features_df = kinematic.create_rate_of_br_column(kinematic_features_df)\n",
    "kinematic_features_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Trajectory Data Preprocessing </h1>\n",
    "\n",
    "<p align = 'justify'>\n",
    "In the form of preprocessing PTRAIL provides:\n",
    "</p>\n",
    "<ul align = 'justify'>\n",
    "<li> Outlier Detection </li>\n",
    "<li> Data filtering based on various constraints </li>\n",
    "<li> Trajectory Interpolation </li>\n",
    "</ul>\n",
    "<p> For interpolation the user needs to provide the type of interpolation. </p>\n",
    "\n",
    "<hr style=\"background-color:black; height:7px\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Outlier Detection and Data Filtering </h2>\n",
    "\n",
    "<p> PTRAIL provides several outlier detection method based on: </p>\n",
    "<ul align='justify'>\n",
    "<li>Distance</li>\n",
    "<li> Speed </li>\n",
    "<li> Trajectory length </li>\n",
    "<li> Hampel filter algorithm </li>\n",
    "</ul>\n",
    "<p> It also provides several filtering methods based on various constraints such as: </p>\n",
    "<ul type = 'square' align='justify'>\n",
    "<li> Date </li>\n",
    "<li> Speed </li>\n",
    "<li> Distance, etc. </li>\n",
    "</ul>\n",
    "<p align = 'justify'> Not all the functions present in the module are demonstrated\n",
    "     here. Only a few of the functions are demonstrated here, keeping\n",
    "     the length of jupyter notebook in mind. Further functions can\n",
    "     be explored in the documentation of the library. The documentation\n",
    "     link is provided in the introduction section of this notebook.\n",
    "</p>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\"\n",
    "    To demonstrate the kinematic features, we will:\n",
    "        1. First, import the filters.py module from the\n",
    "           preprocessing package.\n",
    "        2. Detect outliers and Filter out data based on \n",
    "            bounding box, date and distance.\n",
    "        3. Print the execution time of the code.\n",
    "\"\"\"\n",
    "from ptrail.preprocessing.filters import Filters as filt\n",
    "\n",
    "# Makes use of hampel filter from preprocessing package for outlier removal\n",
    "outlier_df = filt.hampel_outlier_detection(seagulls_df, column_name='lat')\n",
    "print(f\"Length of original: {len(seagulls_df)}\")\n",
    "print(f\"Length after outlier removal: {len(outlier_df)}\")\n",
    "print(f\"Number of points removed: {len(seagulls_df) - len(outlier_df)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Filters and gives out data contained within the given bounding box\n",
    "filter_df_bbox = filt.filter_by_bounding_box(seagulls_df, (61, 24, 65, 25))\n",
    "print(f\"Length of original: {len(seagulls_df)}\")\n",
    "print(f\"Length of data in the bounding box: {len(filter_df_bbox)}\")\n",
    "print(f\"Number of points removed: {len(seagulls_df) - len(filter_df_bbox)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Gives out the points contained within the given date range\n",
    "filter_df_date = filt.filter_by_date(temporal_features_df, start_date='2009-05-28', end_date='2009-06-30')\n",
    "print(f\"Length of original: {len(temporal_features_df)}\")\n",
    "print(f\"Length of data within specified date: {len(filter_df_date)}\")\n",
    "print(f\"Number of points removed: {len(temporal_features_df) - len(filter_df_date)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Filtered dataset with a given maximum distance \n",
    "filter_df_distance = filt.filter_by_max_consecutive_distance(kinematic_features_df, max_distance=4500)\n",
    "print(f\"Length of original: {len(kinematic_features_df)}\")\n",
    "print(f\"Length of Max distance Filtered DF: {len(filter_df_distance)}\")\n",
    "print(f\"Number of points removed: {len(kinematic_features_df) - len(filter_df_distance)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Trajectory Interpolation </h2>\n",
    "\n",
    "<p align='justify'>\n",
    "As mentioned above, for the first time in the community, PTRAIL\n",
    "offers <b><i> four different Interpolation Techniques </i></b> built\n",
    "into it.\n",
    "\n",
    "Trajectory Interpolation is widely used when the trajectory data\n",
    "on hand is not clean and has several Jumps in it which makes the\n",
    "trajectory abrupt. Using interpolation techniques, those jumps\n",
    "between the trajectory points can be filled in order to make the\n",
    "trajectory smoother.\n",
    "\n",
    "PTRAIL offers  following four interpolation techniques:\n",
    "</p>\n",
    "<ol align='justify'>\n",
    "<i>\n",
    "<li> Linear Interpolation </li>\n",
    "<li> Cubic Interpolation </li>\n",
    "<li> Random-Walk Interpolation </li>\n",
    "<li> Kinematic Interpolation </li>\n",
    "</i>\n",
    "</ol>\n",
    "\n",
    "In the examples of interpolation provided in this notebook, the\n",
    "examples are demonstrated on a single trajectory selected from the\n",
    "seagulls dataset. However, it is to be noted that the interpolation\n",
    "works equally well on datasets containing several trajectories.\n",
    "\n",
    "<h3> Note </h3>\n",
    "<p align='justify'>\n",
    "Furthermore, it is also worthwhile to note that PTRAIL only\n",
    "interpolates 4 fundamental columns i.e., <i><b> Latitude, Longitude,\n",
    "DateTime and Trajectory ID </b></i>. Hence, the dataframe returned\n",
    "by the interpolation methods only contain the above mentioned 4\n",
    "columns. This decision is taken while keeping the following point\n",
    "in mind that it is not possible to interpolate other kinds of\n",
    "data that may or may not be present in the dataset.\n",
    "</p>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    First, the following operations are performed:\n",
    "        1. Import the necessary interpolation modules\n",
    "           from the preprocessing package.\n",
    "        2. Select a single trajectory ID from the seagulls\n",
    "           dataset and then plot it using folium.\n",
    "        3. The number of points having time jump greater than\n",
    "           4 hours between 2 points is also calculated and shown.\n",
    "\"\"\"\n",
    "import ptrail.utilities.constants as const\n",
    "import folium\n",
    "from ptrail.preprocessing.interpolation import Interpolation as ip\n",
    "\n",
    "small_seagulls = seagulls_df.reset_index().loc[seagulls_df.reset_index()[const.TRAJECTORY_ID] == '91732'][[const.TRAJECTORY_ID, const.DateTime, const.LAT, const.LONG]]\n",
    "time_del = small_seagulls.reset_index()[const.DateTime].diff().dt.total_seconds()\n",
    "print((time_del > 3600*4).value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Here, we plot the smaller trajectory on a folium map.\n",
    "sw = small_seagulls[['lat', 'lon']].min().values.tolist()\n",
    "ne = small_seagulls[['lat', 'lon']].max().values.tolist()\n",
    "coords = [zip(small_seagulls[const.LAT], small_seagulls[const.LONG])]\n",
    "m1 = folium.Map(location=[small_seagulls[const.LAT].iloc[0], small_seagulls[const.LONG].iloc[0]], zoom_start=1000)\n",
    "\n",
    "folium.PolyLine(coords,\n",
    "                color='blue',\n",
    "                weight=2,\n",
    "                opacity=0.7).add_to(m1)\n",
    "m1.fit_bounds([sw, ne])\n",
    "m1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\"\n",
    "    Now, to demonstrate interpolation, the following steps\n",
    "    are taken:\n",
    "        1. Interpolate the selected trajectory using all of\n",
    "           the above mentioned techniques and print their\n",
    "           execution times along with them.\n",
    "        2. Then, plot all the trajectories side by side along\n",
    "           with the original trajectory on a scatter plot to\n",
    "           see how the time jumps are filled and the points\n",
    "           are inserted into the trajectory.\n",
    "\"\"\"\n",
    "\n",
    "# First, linear interpolation is performed.\n",
    "linear_ip_gulls = ip.interpolate_position(dataframe=small_seagulls,\n",
    "                                          time_jump=3600*4,\n",
    "                                          ip_type='linear')\n",
    "print(f\"Original DF Length: {len(small_seagulls)}\")\n",
    "print(f\"Interpolated DF Length: {len(linear_ip_gulls)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "# Now, cubic interpolation is performed.\n",
    "cubic_ip_gulls = ip.interpolate_position(dataframe=small_seagulls,\n",
    "                                         time_jump=3600*4,\n",
    "                                         ip_type='cubic')\n",
    "print(f\"Original DF Length: {len(small_seagulls)}\")\n",
    "print(f\"Interpolated DF Length: {len(cubic_ip_gulls)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "# Now, random-walk interpolation is performed.\n",
    "rw_ip_gulls = ip.interpolate_position(dataframe=small_seagulls,\n",
    "                                      time_jump=3600*4,\n",
    "                                      ip_type='random-walk')\n",
    "print(f\"Original DF Length: {len(small_seagulls)}\")\n",
    "print(f\"Interpolated DF Length: {len(rw_ip_gulls)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "# Now, kinematic interpolation is performed.\n",
    "kin_ip_gulls = ip.interpolate_position(dataframe=small_seagulls,\n",
    "                                       time_jump=3600*4,\n",
    "                                       ip_type='kinematic')\n",
    "print(f\"Original DF Length: {len(small_seagulls)}\")\n",
    "print(f\"Interpolated DF Length: {len(kin_ip_gulls)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Now, plotting all the scatter plots side by side\n",
    "    in order to compare the interpolation techniques.\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.scatter(small_seagulls[const.LAT],\n",
    "            small_seagulls[const.LONG],\n",
    "            s=15, color='purple')\n",
    "plt.title('Original Trajectory', color='black', size=15)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(25, 20))\n",
    "\n",
    "ax[0, 0].scatter(linear_ip_gulls[const.LAT],\n",
    "                 linear_ip_gulls[const.LONG],\n",
    "                 s=50, color='red')\n",
    "ax[0, 0].set_title('Linear Interpolation', color='black', size=40)\n",
    "ax[0, 1].scatter(cubic_ip_gulls[const.LAT],\n",
    "                 cubic_ip_gulls[const.LONG],\n",
    "                 s=50, color='orange')\n",
    "ax[0, 1].set_title('Cubic Interpolation', color='black', size=40)\n",
    "ax[1, 0].scatter(rw_ip_gulls[const.LAT],\n",
    "                 rw_ip_gulls[const.LONG],\n",
    "                 s=50, color='blue')\n",
    "ax[1, 0].set_title('Random-Walk Interpolation', color='black', size=40)\n",
    "ax[1, 1].scatter(kin_ip_gulls[const.LAT],\n",
    "                 kin_ip_gulls[const.LONG],\n",
    "                 s=50, color='brown')\n",
    "ax[1, 1].set_title('Kinematic Interpolation', color='black', size=40)\n",
    "\n",
    "for plot in enumerate(ax.flat):\n",
    "    plot[1].set_xlabel('Latitude', color='grey', size=25)\n",
    "    plot[1].set_ylabel('Longitude', color='grey', size=25)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}