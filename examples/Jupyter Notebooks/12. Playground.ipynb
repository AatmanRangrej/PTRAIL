{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Dataset Facts ------------------------------\n",
      "\n",
      "Number of unique Trajectories in the data: 253\n",
      "Number of points in the data: 287136\n",
      "Dataset time range: 1196 days 22:51:45\n",
      "Datatype of the DataFrame: <class 'ptrail.core.TrajectoryDF.PTRAILDataFrame'>\n",
      "Dataset Bounding Box: (45.18896978643169, -118.61020848239596, 45.314545642992, -118.50455596234036)\n",
      "\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from ptrail.core.TrajectoryDF import PTRAILDataFrame\n",
    "from ptrail.features.kinematic_features import KinematicFeatures\n",
    "from ptrail.preprocessing.filters import Filters\n",
    "from ptrail.preprocessing.interpolation import Interpolation\n",
    "from ptrail.features.temporal_features import TemporalFeatures\n",
    "\n",
    "\"\"\"\n",
    "    So what I am planning to do for this notebook is that we will\n",
    "    first try to perform classification of Species of the Starkey\n",
    "    dataset using the original dataset only and plot it using\n",
    "    matplotlib and see what the results look like.\n",
    "\n",
    "    Next, we will use PTRAIL to generate features on the starkey\n",
    "    dataset and then we will again perform the same kind of\n",
    "    classification performed above to see the difference and how\n",
    "    the features generated by us help in making the classification\n",
    "    process better.\n",
    "\"\"\"\n",
    "\n",
    "pdf = pd.read_csv('./starkey_new.csv')\n",
    "starkey = PTRAILDataFrame(data_set=pdf,\n",
    "                          latitude='lat',\n",
    "                          longitude='lon',\n",
    "                          datetime='DateTime',\n",
    "                          traj_id='Id')\n",
    "print(starkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yjharanwala/Desktop/PTRAIL/ptrail/preprocessing/filters.py:762: UserWarning: If kinematic features have been generated on the dataframe, then make sure to generate them again as outlier detection drops the point from the dataframe and does not run the kinematic features again.\n",
      "  warnings.warn(\"If kinematic features have been generated on the dataframe, then make \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.16 s, sys: 1.33 s, total: 9.5 s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Now applying a full pipeline of feature generation and data cleanup\n",
    "# using PTRAIL.\n",
    "\n",
    "# 1. Create a distance column based on which we will remove\n",
    "# outlier using hampel filter.\n",
    "starkey = KinematicFeatures.create_distance_column(dataframe=starkey)\n",
    "\n",
    "# 2. Applying hampel filter.\n",
    "filt_starkey = Filters.hampel_outlier_detection(dataframe=starkey,\n",
    "                                                column_name='Distance')\n",
    "\n",
    "# 3. Now, interpolate the trajectories using linear Interpolation.\n",
    "ip_starkey = Interpolation.interpolate_position(dataframe=filt_starkey,\n",
    "                                                time_jump=3600*2,\n",
    "                                                ip_type='linear')\n",
    "\n",
    "# 4. Now, generate kinematic and temporal features on the\n",
    "# interpolated dataset.\n",
    "feat_starkey = KinematicFeatures.generate_kinematic_features(dataframe=ip_starkey)\n",
    "feat_starkey = TemporalFeatures.generate_temporal_features(dataframe=feat_starkey)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Now, we create test and train datasets. The train dataset includes\n",
    "# 33% of all the unique trajectories in the dataset and the test\n",
    "# contains the rest.\n",
    "import random\n",
    "import progressbar\n",
    "import datetime as dt\n",
    "\n",
    "def dtt2timestamp(dtt):\n",
    "    ts = (dtt.hour * 60 + dtt.minute) * 60 + dtt.second\n",
    "    #if you want microseconds as well\n",
    "    ts += dtt.microsecond * 10**(-6)\n",
    "    return ts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169\n",
      "84\n"
     ]
    }
   ],
   "source": [
    "taken = []\n",
    "train_33 = []\n",
    "test_66 = []\n",
    "\n",
    "total = feat_starkey.traj_id.unique().tolist()\n",
    "len(total)\n",
    "\n",
    "iterator = 0\n",
    "while iterator != len(total)//3:\n",
    "    index = random.randint(0, len(total))\n",
    "    if index not in taken:\n",
    "        train_33.append(total[index])\n",
    "        taken.append(index)\n",
    "        iterator += 1\n",
    "\n",
    "for i in range(len(total)):\n",
    "    if total[i] not in train_33:\n",
    "        test_66.append(total[i])\n",
    "\n",
    "print(len(test_66))\n",
    "print(len(train_33))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ |  #                                              | 168 Elapsed Time: 0:00:29"
     ]
    }
   ],
   "source": [
    "test_chunks = []\n",
    "\n",
    "bar = progressbar.ProgressBar(max_value=progressbar.UnknownLength)\n",
    "for i in range(len(test_66)):\n",
    "    small = feat_starkey.reset_index().loc[feat_starkey.reset_index().traj_id == test_66[i]]\n",
    "\n",
    "    if 'D' in test_66[i]:\n",
    "        small['Species'] = 0\n",
    "    elif 'E' in test_66[i]:\n",
    "        small['Species'] = 1\n",
    "    else:\n",
    "        small['Species'] = 2\n",
    "\n",
    "    small['Date'] = small['Date'].map(dt.datetime.toordinal)\n",
    "    small['Time'] = small['Time'].apply(dtt2timestamp)\n",
    "    small = small.drop(columns=['Day_Of_Week', 'Time_Of_Day'])\n",
    "\n",
    "    test_chunks.append(small)\n",
    "    bar.update(i)\n",
    "\n",
    "test_df = PTRAILDataFrame(data_set=pd.concat(test_chunks).dropna(),\n",
    "                          latitude='lat',\n",
    "                          longitude='lon',\n",
    "                          datetime='DateTime',\n",
    "                          traj_id='Id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                                       #          | 83 Elapsed Time: 0:00:13"
     ]
    }
   ],
   "source": [
    "train_chunks = []\n",
    "\n",
    "bar = progressbar.ProgressBar(max_value=progressbar.UnknownLength)\n",
    "for i in range(len(train_33)):\n",
    "    small = feat_starkey.reset_index().loc[feat_starkey.reset_index().traj_id == train_33[i]]\n",
    "\n",
    "    if 'D' in train_33[i]:\n",
    "        small['Species'] = 0\n",
    "    elif 'E' in train_33[i]:\n",
    "        small['Species'] = 1\n",
    "    else:\n",
    "        small['Species'] = 2\n",
    "    small['Date'] = small['Date'].map(dt.datetime.toordinal)\n",
    "    small['Time'] = small['Time'].apply(dtt2timestamp)\n",
    "    small = small.drop(columns=['Day_Of_Week', 'Time_Of_Day'])\n",
    "\n",
    "    train_chunks.append(small)\n",
    "    bar.update(i)\n",
    "\n",
    "train_df = PTRAILDataFrame(data_set=pd.concat(train_chunks).dropna(),\n",
    "                          latitude='lat',\n",
    "                          longitude='lon',\n",
    "                          datetime='DateTime',\n",
    "                          traj_id='Id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier()"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(train_df.drop(columns=['Species']),\n",
    "             train_df['Species'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target on train data: [0 0 0 ... 2 2 2]\n",
      "Target on test data: [0 0 0 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Now, lets predict the Species on the train and test dataset.\n",
    "rf_predict_train = rf_model.predict(train_df.drop(columns=['Species']))\n",
    "print(f\"Target on train data: {rf_predict_train}\")\n",
    "\n",
    "rf_predict_test = rf_model.predict(test_df.drop(columns=['Species']))\n",
    "print(f\"Target on test data: {rf_predict_test}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training accuracy of RF is: 100.0%\n",
      "The Testing accuracy of RF is: 77.1181729647943%\n"
     ]
    }
   ],
   "source": [
    "rf_train_accuracy = accuracy_score(train_df['Species'], rf_predict_train)\n",
    "print(f\"The Training accuracy of RF is: {rf_train_accuracy*100}%\")\n",
    "\n",
    "rf_test_accuracy = accuracy_score(test_df['Species'], rf_predict_test)\n",
    "print(f\"The Testing accuracy of RF is: {rf_test_accuracy*100}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}